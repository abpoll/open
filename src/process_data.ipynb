{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2008807c",
   "metadata": {},
   "source": [
    "# Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3bda1a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T14:57:54.759756Z",
     "start_time": "2023-09-12T14:57:54.752803Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries for loading data, analysis and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from os.path import join\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd84a2c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T14:54:55.617866Z",
     "start_time": "2023-09-12T14:54:55.610101Z"
    }
   },
   "outputs": [],
   "source": [
    "# This gets you to your code directory\n",
    "path = Path.cwd()\n",
    "# This gets you to your project directory\n",
    "ROOT_DIR = path.parent.absolute()\n",
    "# Root for data directories\n",
    "r_fr = join(ROOT_DIR, 'data', 'raw')\n",
    "r_fi = join(ROOT_DIR, 'data', 'interim')\n",
    "r_fp = join(ROOT_DIR, 'data', 'processed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a838d02",
   "metadata": {},
   "source": [
    "# Get list of journals for review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba33346c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T14:53:42.500542Z",
     "start_time": "2023-09-12T14:53:42.468409Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the list of 50 journals\n",
    "j_df = pd.read_csv(join(r_fi, 'JCR_SCIE_Filtered.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e8ecb5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T14:53:42.659954Z",
     "start_time": "2023-09-12T14:53:42.650603Z"
    }
   },
   "outputs": [],
   "source": [
    "# First, we drop any journals that are mostly reviews,\n",
    "# perspectives, comments, opinions\n",
    "drop_col = j_df.columns[-1]\n",
    "j_keep = j_df.loc[j_df[drop_col] != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0af5d39a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T14:53:42.960024Z",
     "start_time": "2023-09-12T14:53:42.930790Z"
    }
   },
   "outputs": [],
   "source": [
    "# Next, we drop on dupliacte publishers and keep first since\n",
    "# the df is sorted from top to bottom by 2022 JIF\n",
    "j_final = j_keep.drop_duplicates(subset='Publisher').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed7954f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T14:53:43.418495Z",
     "start_time": "2023-09-12T14:53:43.411342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Journals to Search: 18\n"
     ]
    }
   ],
   "source": [
    "print('Number of Journals to Search: ' + str(len(j_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b934840b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T14:53:44.174898Z",
     "start_time": "2023-09-12T14:53:44.167689Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get ISSN and eISSN merged for search\n",
    "j_final['IS'] = np.where(j_final['ISSN'].notnull(),\n",
    "                         j_final['ISSN'],\n",
    "                         j_final['eISSN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2ffb5da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T14:53:45.174797Z",
     "start_time": "2023-09-12T14:53:45.166171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of IS to use in searches:\n",
      "\n",
      "0     1754-5692\n",
      "1     1758-678X\n",
      "2     2542-5196\n",
      "3     2590-3330\n",
      "4     1610-3653\n",
      "5     0034-4257\n",
      "6     0043-1354\n",
      "7     2524-7972\n",
      "8     1354-1013\n",
      "9     0013-936X\n",
      "10    0091-6765\n",
      "11    0301-4797\n",
      "12    0013-9351\n",
      "13    2328-4277\n",
      "14    2662-4435\n",
      "15    1674-9278\n",
      "16    1726-2135\n",
      "17    1001-0742\n",
      "Name: IS, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('List of IS to use in searches:\\n')\n",
    "print(j_final['IS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8f8d222",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T14:53:46.790719Z",
     "start_time": "2023-09-12T14:53:46.780775Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a column of how many articles fit the search \n",
    "# in the sample after checking the search on WOS\n",
    "# (IS=IS) AND (TS=clim*) AND ((PY=2021) OR (PY=2022))\n",
    "# then subsetting to article types. We want to keep journals that\n",
    "# have published at least 30 articles according to this search criteria\n",
    "article_list = [27, 244, 64, 71, 10, 321, 125, 5, 770,\n",
    "                298, 15, 808, 310, 332, 270, 119, 14, 34]\n",
    "num_articles = pd.Series(article_list, name='n_articles')\n",
    "j_final = j_final.assign(n_articles=num_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0345d64e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T14:54:22.911369Z",
     "start_time": "2023-09-12T14:54:22.868168Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the review,etc. column and write out the dataframe into processed\n",
    "j_final.drop(columns=drop_col).to_csv(join(r_fp, 'journals_to_search.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262bbd1d",
   "metadata": {},
   "source": [
    "# Process articles from journal searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d01cd68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T15:10:53.866390Z",
     "start_time": "2023-09-12T15:10:53.606553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "savedrecs_0013-936X.txt\n",
      "savedrecs_0034-4257.txt\n",
      "savedrecs_2662-4435.txt\n",
      "savedrecs_1001-0742.txt\n",
      "savedrecs_1354-1013.txt\n",
      "savedrecs_1758-678X.txt\n",
      "savedrecs_0013-9351.txt\n",
      "savedrecs_0043-1354.txt\n",
      "savedrecs_1674-9278.txt\n",
      "savedrecs_2328-4277.txt\n",
      "savedrecs_0301-4797.txt\n",
      "savedrecs_2590-3330.txt\n",
      "savedrecs_2542-5196.txt\n"
     ]
    }
   ],
   "source": [
    "# Loop through the raw/articles/ directory\n",
    "# to create a dataframe of the articles we need to check\n",
    "# for open data and code\n",
    "art_dir = join(r_fr, 'articles')\n",
    "\n",
    "# For each file in this directory, pd.read_csv with\n",
    "# tab delim. Add to list of dfs and concat at the end\n",
    "df_list = []\n",
    "for file in os.listdir(art_dir):\n",
    "    # Skip dot files\n",
    "    if file[0] != '.':\n",
    "        filepath = join(art_dir, file)\n",
    "        temp = pd.read_csv(filepath, sep='\\t')\n",
    "        df_list.append(temp)\n",
    "        print(file)\n",
    "articles = pd.concat(df_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "958d5fd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T15:13:11.498651Z",
     "start_time": "2023-09-12T15:13:11.459228Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subset to columns of interest for search\n",
    "# columns are described here \n",
    "# http://webofscience.help.clarivate.com/en-us/Content/export-records.htm\n",
    "# under All Export Field Tags\n",
    "# We want to keep \n",
    "# AU: Authors or Inventors\n",
    "# TI: Article Title\n",
    "# SO: Source Title (Journal title)\n",
    "# DT: Document Type\n",
    "# TC: Times Cited Count\n",
    "# DI: DOI\n",
    "# DL: DOI Link\n",
    "col_keep = ['AU', 'TI', 'SO', 'DT', 'TC', 'DI', 'DL', 'PY']\n",
    "col_names = ['authors', 'title', 'journal', 'doc_type', 'total_cited',\n",
    "             'doi', 'doi_link', 'pub_year']\n",
    "articles_f = articles.loc[:, col_keep]\n",
    "articles_f.columns = col_names\n",
    "\n",
    "# Subset to articles with > 20 citations\n",
    "articles_f = articles_f[articles_f['total_cited'] >= 20]\n",
    "\n",
    "# Write out to interim\n",
    "articles_f.to_csv(join(r_fi, 'articles.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.5",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
