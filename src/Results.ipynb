{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da0497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:27:20.029485Z",
     "start_time": "2023-11-22T00:27:05.815031Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries for loading data, analysis and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e776a60",
   "metadata": {},
   "source": [
    "# Load Review Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd3b722",
   "metadata": {},
   "source": [
    "Load and filter data for analysis/visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763f54b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:27:20.041671Z",
     "start_time": "2023-11-22T00:27:20.035450Z"
    }
   },
   "outputs": [],
   "source": [
    "# This gets you to your code directory\n",
    "path = Path.cwd()\n",
    "# This gets you to your project directory\n",
    "ROOT_DIR = path.parent.absolute()\n",
    "# Root for data directory\n",
    "r_fp = join(ROOT_DIR, 'data', 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e6c4d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:27:20.223130Z",
     "start_time": "2023-11-22T00:27:20.045766Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read review data\n",
    "open_df = pd.read_csv(join(r_fp, 'articles_reviewed.csv'),\n",
    "                      encoding='latin1')\n",
    "# Drop articles with dropped == 1\n",
    "open_df = open_df[open_df['dropped'] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5718e92e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:27:20.252112Z",
     "start_time": "2023-11-22T00:27:20.227471Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read journal data and get 2022 JIF\n",
    "journals = pd.read_csv(join(r_fp, 'journals_to_search.csv'))\n",
    "\n",
    "# Make Journal name column in journals all upper case\n",
    "# Get dict of this to 2022 JIF column\n",
    "jif_dict = dict(zip(journals['Journal name'].str.upper(),\n",
    "                    journals['2022 JIF']))\n",
    "\n",
    "# After doing grouping and pivots for summary stats and plotting,\n",
    "# we will use this dict to get JIF linked "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73d3171",
   "metadata": {},
   "source": [
    "## Use data and code included to get final categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc4d591",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:27:41.822112Z",
     "start_time": "2023-11-22T00:27:41.795934Z"
    }
   },
   "outputs": [],
   "source": [
    "# For the partially closed classifications, there are some\n",
    "# papers worth identifying as closer to open than the others\n",
    "\n",
    "# For data, we will relabel the following as \n",
    "# \"Mostly open, additional barriers to reproduction\"\n",
    "# All \n",
    "# Raw; Results; Source Data \n",
    "# Raw; Results\n",
    "# These are categories where there are obstacles to immediate access\n",
    "# (need permission to download from repo, need to track down raw from\n",
    "# URLs) but there could be -- with all the code -- enough. It's ambiguous\n",
    "# but worth coding differently to acknowledge they are not open, but also\n",
    "# not the same as studies with substantial barriers to the ethos\n",
    "# of openness\n",
    "# The other categories are\n",
    "# Open, unique and persistent repository\n",
    "# Mostly closed, substantial barriers to reproduction\n",
    "# Closed\n",
    "# These are defined in terms of Open, Partially Closed (but not the other \n",
    "# category), and Closed, respectively \n",
    "\n",
    "# For the purposes of transforming and processing data, these column\n",
    "# names present a challenge, so we will also use a col_name_dict\n",
    "# Use open, mostly_open, mostly_closed, closed as keys\n",
    "col_name_dict = {'open': 'Open',\n",
    "                 'mostly_open': 'Mostly open',\n",
    "                 'mostly_closed': 'Mostly closed',\n",
    "                 'closed': 'Closed'}\n",
    "\n",
    "\n",
    "open_df.loc[open_df['data_open'] == 'Open',\n",
    "            'data_cat'] = 'open'\n",
    "\n",
    "open_df.loc[(open_df['data_open'] == 'Partially Closed'),\n",
    "            'data_cat'] = 'mostly_closed'\n",
    "data_cats = ['All', 'Raw; Results; Source Data', 'Raw; Results']\n",
    "open_df.loc[(open_df['data_open'] == 'Partially Closed') &\n",
    "            (open_df['data_included'].isin(data_cats)),\n",
    "            'data_cat'] = 'mostly_open'\n",
    "open_df.loc[(open_df['data_open'] == 'Closed'),\n",
    "            'data_cat'] = 'closed'\n",
    "\n",
    "# Similarly, for code, \n",
    "# All\n",
    "# Download; Process; Analysis; Figures\n",
    "# Processing; Generate Results\n",
    "# Processing; Results\n",
    "# Since these have issues like GitHub instead of \n",
    "# persistent & unique identifier, or being potentially enough\n",
    "# to reproduce (but depends on data & how much the code actually gets you)\n",
    "open_df.loc[open_df['code_open'] == 'Open',\n",
    "            'code_cat'] = 'open'\n",
    "\n",
    "open_df.loc[(open_df['code_open'] == 'Partially Closed'),\n",
    "            'code_cat'] = 'mostly_closed'\n",
    "code_cats = ['All', 'Download; Process; Analysis; Figures',\n",
    "             'Processing; Generate Results', 'Processing; Results',\n",
    "             'Models; Results', 'Models; Analysis', 'Analysis; Figures',\n",
    "             'Model; Figures', 'Results; Figures', 'Generate Results; Figures']\n",
    "open_df.loc[(open_df['code_open'] == 'Partially Closed') &\n",
    "            (open_df['code_included'].isin(code_cats)),\n",
    "            'code_cat'] = 'mostly_open'\n",
    "open_df.loc[(open_df['code_open'] == 'Closed'),\n",
    "            'code_cat'] = 'closed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9a6f9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-17T15:48:29.591402Z",
     "start_time": "2023-07-17T15:48:29.543337Z"
    }
   },
   "source": [
    "# Summarize Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3feb3d",
   "metadata": {},
   "source": [
    "## Get summary statistics overall and by journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7dfec1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:27:43.474109Z",
     "start_time": "2023-11-22T00:27:43.452051Z"
    }
   },
   "outputs": [],
   "source": [
    "# Overall data and code\n",
    "print(open_df['data_cat'].value_counts())\n",
    "print()\n",
    "print(open_df['code_cat'].value_counts())\n",
    "print()\n",
    "\n",
    "print(open_df['data_cat'].value_counts()/len(open_df))\n",
    "print()\n",
    "print(open_df['code_cat'].value_counts()/len(open_df))\n",
    "print()\n",
    "\n",
    "\n",
    "# Check that there are no missing records\n",
    "check = (open_df['data_cat'].value_counts().sum() ==\n",
    "         open_df['code_cat'].value_counts().sum())\n",
    "\n",
    "if check:\n",
    "    print('Continue :)')\n",
    "else:\n",
    "    print('STOP!!!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e951ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(open_df.groupby(['data_cat', 'code_cat']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d9ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(open_df.groupby(['data_cat', 'code_cat']).size()/len(open_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685d84c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:27:45.186344Z",
     "start_time": "2023-11-22T00:27:45.125704Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get a dataframe of data openness by journal\n",
    "# Can use any column as the values argument since\n",
    "# the data is one record per row\n",
    "data_byj = open_df.pivot_table(columns=['data_cat'], index=['journal'], \n",
    "                               values=['authors'], aggfunc='count').fillna(0)\n",
    "\n",
    "# Get a dataframe of code openness by journal\n",
    "code_byj = open_df.pivot_table(columns=['code_cat'], index=['journal'],\n",
    "                               values=['authors'], aggfunc='count').fillna(0)\n",
    "\n",
    "# Rest indices\n",
    "data_byj = data_byj.reset_index()\n",
    "code_byj = code_byj.reset_index()\n",
    "# Map in the 2022 JIF column\n",
    "data_byj['jif'] = data_byj['journal'].map(jif_dict)\n",
    "code_byj['jif'] = code_byj['journal'].map(jif_dict)\n",
    "\n",
    "# Get number of articles reviewed per journal\n",
    "jsize_df = open_df['journal'].value_counts().reset_index()\n",
    "jcount_dict = dict(zip(jsize_df['journal'], jsize_df['count']))\n",
    "# Map these numbers into data_byj and code_byj\n",
    "data_byj['n_rev'] = data_byj['journal'].map(jcount_dict)\n",
    "code_byj['n_rev'] = code_byj['journal'].map(jcount_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4c3bb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:27:45.659003Z",
     "start_time": "2023-11-22T00:27:45.616210Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get proportions for each category based on n_rev\n",
    "# and print wiht journal in the index\n",
    "j_prop_d = ((data_byj.iloc[:, 1:5].T)/data_byj.iloc[:,-1]).T\n",
    "j_prop_d_df = j_prop_d.set_index(data_byj['journal']).reset_index()\n",
    "# Map in the jif to the prop df\n",
    "j_prop_d_df['jif'] = j_prop_d_df['journal'].map(jif_dict)\n",
    "print('Proportions\\n')\n",
    "# view the proportions\n",
    "# look at printed table from next cell to verify\n",
    "j_prop_d.set_index(data_byj['journal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b420ce87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:27:46.699837Z",
     "start_time": "2023-11-22T00:27:46.666123Z"
    }
   },
   "outputs": [],
   "source": [
    "# look at counts table for data to verify\n",
    "data_byj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef70d99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:27:47.182931Z",
     "start_time": "2023-11-22T00:27:47.140382Z"
    }
   },
   "outputs": [],
   "source": [
    "# Repeat for code\n",
    "j_prop_c = ((code_byj.iloc[:, 1:5].T)/code_byj.iloc[:,-1]).T\n",
    "j_prop_c_df = j_prop_c.set_index(code_byj['journal']).reset_index()\n",
    "# Map in the jif to the prop df\n",
    "j_prop_c_df['jif'] = j_prop_c_df['journal'].map(jif_dict)\n",
    "print('Proportions\\n')\n",
    "# view the proportions\n",
    "# look at printed table from next cell to verify\n",
    "j_prop_c.set_index(code_byj['journal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1334e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:27:48.308926Z",
     "start_time": "2023-11-22T00:27:48.273826Z"
    }
   },
   "outputs": [],
   "source": [
    "code_byj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f43cb1",
   "metadata": {},
   "source": [
    "## Plot the journal-level results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea2917",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:27:52.944823Z",
     "start_time": "2023-11-22T00:27:52.895862Z"
    }
   },
   "outputs": [],
   "source": [
    "# Keep cols\n",
    "# This is the order of the cols in j_prop_c_df \n",
    "# and j_prop_d_df\n",
    "keep_cols = ['closed',\n",
    "             'mostly_closed',\n",
    "             'mostly_open',\n",
    "             'open']\n",
    "\n",
    "# Mapping Journal Acronyms to Abbreviations\n",
    "name_dict = {\n",
    "    'NCC': \"Nat Clim\\nChange\",\n",
    "    'LPH': \"Lancet\\nPlan Hlth\",\n",
    "    'EF': \"Earth's\\nFuture\",\n",
    "    'GCB': \"Glb Chg\\nBio\",\n",
    "    'CE&E': \"Comm\\nE&E\",\n",
    "    'OE': \"One\\nEarth\",\n",
    "    'RSOE': \"Rem Sens\\nEnv\",\n",
    "    'WR': \"Water\\nRes\",\n",
    "    'ES&T': \"Env Sci\\n&Tech\",\n",
    "    'JOEM': \"Jrnl Env\\nMgmt\",\n",
    "    'ER': \"Env\\nRes\"\n",
    "}\n",
    "\n",
    "# Mapping Journal Acronyms to Standards\n",
    "# Need to copy/paste all these\n",
    "# into supplementary info where we\n",
    "# summarize the standards\n",
    "# The main thing to capture is the very minimal notion\n",
    "# of whether anything is said at all about data &\n",
    "# code availability. It is hard to navigate the subjective\n",
    "# notion of \"strength\" of requirements. We objectively track\n",
    "# the strength with the core aspect of our review.\n",
    "# So here, we just look at who even says anything. \n",
    "# Generally, the language is more like \"encourage\"\n",
    "# than \"mandate\" but even within a particular \n",
    "# standard it varies in strength (i.e. encourage & require\n",
    "# are often seen together, so an objective mapping is\n",
    "# not easy to do)\n",
    "\n",
    "# References for this\n",
    "# NCC & CE&E: https://www.nature.com/nature-portfolio/\n",
    "# editorial-policies/reporting-standards\n",
    "# Data & Code\n",
    "# (Spring Nature requires, journals link to)\n",
    "\n",
    "# Earth's Future: https://www.agu.org/publish-with-agu/publish/\n",
    "# author-resources/data-and-software-for-authors\n",
    "# Data & Code\n",
    "# (AGU requires, journal links to)\n",
    "\n",
    "# Lancet Planetary Health\n",
    "# https://www.thelancet.com/pb-assets/Lancet/\n",
    "# authors/tlplanet-info-for-authors.pdf\n",
    "# Data \n",
    "\n",
    "# Global Change Biology\n",
    "# https://onlinelibrary.wiley.com/page/journal/13652486/homepage/\n",
    "# forauthors.html\n",
    "# Data and code\n",
    "\n",
    "# One Earth\n",
    "# https://www.cell.com/one-earth/author\n",
    "# Data and code\n",
    "\n",
    "# Remote sensing of the environment\n",
    "# https://www.sciencedirect.com/journal/remote-sensing-of-environment/\n",
    "# publish/guide-for-authors\n",
    "# Data (very light)\n",
    "\n",
    "# Water research\n",
    "# https://www.sciencedirect.com/journal/\n",
    "# water-research/publish/guide-for-authors\n",
    "# Data and code (uses the word \"requires\" and offers\n",
    "# many resources to abide)\n",
    "\n",
    "# Env. Sci. and Technology\n",
    "# https://publish.acs.org/publish/author_guidelines?coden=esthag\n",
    "# Data and code\n",
    "\n",
    "# Journal of Environmental Management\n",
    "# https://www.sciencedirect.com/journal/journal-of-environmental-management/\n",
    "# publish/guide-for-authors\n",
    "# Data\n",
    "\n",
    "# Journal of Environmental Management\n",
    "# https://www.sciencedirect.com/journal/environmental-research/\n",
    "# publish/guide-for-authors\n",
    "# Data\n",
    "\n",
    "# Data\n",
    "data_name_dict = {\n",
    "    'NCC': \"Yes\",\n",
    "    'LPH': \"Yes\",\n",
    "    'EF': \"Yes\",\n",
    "    'GCB': \"Yes\",\n",
    "    'CE&E': \"Yes\",\n",
    "    'OE': \"Yes\",\n",
    "    'RSOE': \"Yes\",\n",
    "    'WR': \"Yes\",\n",
    "    'ES&T': \"Yes\",\n",
    "    'JOEM': \"Yes\",\n",
    "    'ER': \"Yes\"\n",
    "}\n",
    "\n",
    "data_name_dict = {\n",
    "    'NCC': \"Yes\",\n",
    "    'LPH': \"No\",\n",
    "    'EF': \"Yes\",\n",
    "    'GCB': \"Yes\",\n",
    "    'CE&E': \"Yes\",\n",
    "    'OE': \"Yes\",\n",
    "    'RSOE': \"Yes\",\n",
    "    'WR': \"Yes\",\n",
    "    'ES&T': \"Yes\",\n",
    "    'JOEM': \"No\",\n",
    "    'ER': \"No\"\n",
    "}\n",
    "\n",
    "# Code\n",
    "\n",
    "# We will sort on these to get order of journals on x-axis\n",
    "sort_col1 = 'open'\n",
    "sort_col2 = 'mostly_open'\n",
    "sort_col3 = 'jif'\n",
    "sort_col = 'open_enough'\n",
    "\n",
    "# Prepare code\n",
    "# We want the x-axis to be an abbrevation/acronym for the journal\n",
    "# and the 2022 JIF in parantheses\n",
    "# We sort by most open from left to right\n",
    "j_prop_c_df.columns = ['journal'] + keep_cols + ['jif']\n",
    "j_prop_c_df[sort_col] = j_prop_c_df[sort_col1] + j_prop_c_df[sort_col2]\n",
    "code_plot = j_prop_c_df.sort_values([sort_col, sort_col3],\n",
    "                                     ascending=False)\n",
    "code_plot['j_acr'] = code_plot['journal'].str.split(' ').apply(lambda x: ''.join([i[0][0] for i in x]))\n",
    "code_plot['acr_jif'] = code_plot['j_acr'].map(name_dict) + '\\n(' + code_plot['jif'].astype(str) + ')'\n",
    "# We only need to keep the openness columns for plotting\n",
    "code_df = code_plot.set_index('acr_jif')[keep_cols]\n",
    "\n",
    "# Repeat for data - also sorted by code openness\n",
    "j_prop_d_df.columns = ['journal'] + keep_cols + ['jif']\n",
    "j_prop_d_df[sort_col] = j_prop_d_df[sort_col1] + j_prop_d_df[sort_col2]\n",
    "data_plot = j_prop_d_df.sort_values([sort_col, sort_col3],\n",
    "                                     ascending=False)\n",
    "data_plot['j_acr'] = data_plot['journal'].str.split(' ').apply(lambda x: ''.join([i[0][0] for i in x]))\n",
    "data_plot['acr_jif'] = data_plot['j_acr'].map(name_dict) + '\\n(' + data_plot['jif'].astype(str) + ')'\n",
    "data_df = data_plot.set_index('acr_jif')[keep_cols]\n",
    "# We reindex on the code_df dataframe index to have\n",
    "# the journals lined up\n",
    "data_df = data_df.reindex(code_df.index)\n",
    "\n",
    "# Get rounded percentages\n",
    "data_df = round(data_df*100, 2)\n",
    "code_df = round(code_df*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c41083",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:27:53.972723Z",
     "start_time": "2023-11-22T00:27:53.949624Z"
    }
   },
   "outputs": [],
   "source": [
    "# look at the data_df\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7aeb18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:27:54.389541Z",
     "start_time": "2023-11-22T00:27:54.365772Z"
    }
   },
   "outputs": [],
   "source": [
    "# check data_df to our first df of proportions\n",
    "# to confirm correctness\n",
    "j_prop_d_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7461dc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:27:56.063335Z",
     "start_time": "2023-11-22T00:27:56.039619Z"
    }
   },
   "outputs": [],
   "source": [
    "# do the same for code\n",
    "code_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752011fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:27:57.502471Z",
     "start_time": "2023-11-22T00:27:57.476971Z"
    }
   },
   "outputs": [],
   "source": [
    "j_prop_c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc44a17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:05.060448Z",
     "start_time": "2023-11-22T00:28:00.236062Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the col_name_dict for figure purposes\n",
    "data_df = data_df.rename(columns=col_name_dict)\n",
    "code_df = code_df.rename(columns=col_name_dict)\n",
    "\n",
    "# Plot on a 1 by 2 axis\n",
    "import matplotlib.ticker as mtick\n",
    "fig, ax = plt.subplots(figsize=(12, 6), nrows=2, \n",
    "                       sharex=True, dpi=600)\n",
    "\n",
    "# Need the dataframes to have a column that indicates\n",
    "# have stated standards vs. don't have stated standards\n",
    "# We would subset these dataframes and plot them\n",
    "# with different color edges around the bins\n",
    "# Maybe red vs. black (red for do not have)\n",
    "\n",
    "data_df.plot(ax=ax[0], kind='bar', stacked=True,\n",
    "             color=['#252525', '#636363', '#d3d3d3', '#f7f7f7'],\n",
    "             edgecolor='black',\n",
    "             legend=False)\n",
    "\n",
    "code_df.plot(ax=ax[1], kind='bar', stacked=True, \n",
    "             lw=[1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2],\n",
    "             color=['#252525', '#636363', '#d3d3d3', '#f7f7f7'],\n",
    "             edgecolor=['black', 'black', 'black', 'black',\n",
    "                        'red', 'black', 'black', 'black',\n",
    "                        'black', 'red', 'red'],\n",
    "             legend=False)\n",
    "\n",
    "\n",
    "ax[1].tick_params(axis='both', labelsize=12)\n",
    "ax[1].set_ylabel('Percentage of Studies', size=14)\n",
    "ax[0].tick_params(axis='both', labelsize=12)\n",
    "ax[0].set_ylabel('Percentage of Studies', size=14)\n",
    "ax[0].tick_params(axis='x', which='both',\n",
    "                  bottom=False)\n",
    "\n",
    "ax[0].set_title('Data Openness (258 Studies)', size=16)\n",
    "ax[1].set_title('Code Openness (258 Studies)', size=16)\n",
    "\n",
    "ax[0].yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "ax[1].yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "\n",
    "handles, labels = ax[1].get_legend_handles_labels()\n",
    "\n",
    "ax[1].legend(reversed(handles),\n",
    "             reversed(labels),\n",
    "             loc='center',\n",
    "             bbox_to_anchor=(0.25, -0.8),\n",
    "             fancybox=False,\n",
    "             shadow=False,\n",
    "             frameon=False,\n",
    "             fontsize='large',\n",
    "             ncol=1)\n",
    "\n",
    "ax[1].set_xlabel('Journal Abbreviation\\n(2022 Journal Impact Factor)',\n",
    "                 size=12,\n",
    "                 labelpad=10)\n",
    "ax[1].set_xticks(ax[1].get_xticks(),\n",
    "                 ax[1].get_xticklabels(),\n",
    "                 rotation=0,\n",
    "                 ha='center')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.25)\n",
    "\n",
    "cax = fig.add_axes([.55, -0.14, 0.3, 0.02])\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "legend_elements = [Patch(facecolor='none', edgecolor='black',\n",
    "                         label='Stated standards about openness'),\n",
    "                Patch(facecolor='none', edgecolor='red', lw=2,\n",
    "                         label='No stated standards about openness')]\n",
    "\n",
    "cax.axis('off')\n",
    "# Create the figure\n",
    "cax.legend(handles=legend_elements, loc='center',\n",
    "          fontsize='large',\n",
    "          fancybox=False,\n",
    "          shadow=False,\n",
    "          frameon=False,\n",
    "          ncol=1)\n",
    "\n",
    "fig.savefig(join(ROOT_DIR, 'fig', 'fig2.png'),\n",
    "            dpi=600,\n",
    "            bbox_inches='tight') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520db56f",
   "metadata": {},
   "source": [
    "## Summarize key features of not open papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f5e709",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:32.747263Z",
     "start_time": "2023-11-22T00:28:32.738234Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's get one df for not open data\n",
    "closed_data = open_df[(open_df['data_cat'] != 'open') &\n",
    "                      (open_df['data_cat'] != 'mostly_open')]\n",
    "\n",
    "# Let's get another df for not open code\n",
    "closed_code = open_df[(open_df['code_cat'] != 'open') &\n",
    "                      (open_df['code_cat'] != 'mostly_open')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48492aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:34.187803Z",
     "start_time": "2023-11-22T00:28:34.178287Z"
    }
   },
   "outputs": [],
   "source": [
    "# number of studies with these data categories\n",
    "len(closed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da1725c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:34.566051Z",
     "start_time": "2023-11-22T00:28:34.557394Z"
    }
   },
   "outputs": [],
   "source": [
    "# number of studies with these code categories\n",
    "len(closed_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa105ef1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:34.952467Z",
     "start_time": "2023-11-22T00:28:34.935932Z"
    }
   },
   "outputs": [],
   "source": [
    "# First, we inspect the reasons that some data was not shared\n",
    "# Most often, no reason is provided\n",
    "# Next most common, studies say they will share upon request or \n",
    "# reasonable request\n",
    "# There are a few rare reasons. Privacy is cited twice, \n",
    "# authors say they don't have permission twice,\n",
    "# one group says they have confidentiality concerns, another says\n",
    "# they are bound to a confidentialy agreement, and another\n",
    "# says they can share after a proposal or data use agreement\n",
    "closed_data['data_reasons'].str.split(';').explode().str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf081232",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:35.892168Z",
     "start_time": "2023-11-22T00:28:35.878132Z"
    }
   },
   "outputs": [],
   "source": [
    "closed_code['code_reasons'].str.split(';').explode().str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191255d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:37.182685Z",
     "start_time": "2023-11-22T00:28:37.166829Z"
    }
   },
   "outputs": [],
   "source": [
    "# In proportions\n",
    "closed_data['data_reasons'].str.split(';').explode().str.strip().value_counts()/len(closed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cda4822",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:37.651880Z",
     "start_time": "2023-11-22T00:28:37.637212Z"
    }
   },
   "outputs": [],
   "source": [
    "closed_code['code_reasons'].str.split(';').explode().str.strip().value_counts()/len(closed_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0da904",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:39.043875Z",
     "start_time": "2023-11-22T00:28:39.024584Z"
    }
   },
   "outputs": [],
   "source": [
    "# Next, we inspect what data is included when a study shares some\n",
    "# but has barriers to openness\n",
    "# Most often, raw data is shared, followed by results (usually model output,\n",
    "# often not clear if it is results from all analyses conducted since \n",
    "# authors often say ambiguous things in their data statements about\n",
    "# what exactly they're sharing and the repositories don't always offer\n",
    "# more guidance)\n",
    "# Source Data -- for figures and tables -- is rarely provided\n",
    "# Very infrequently, All data is provided, it just is in a repo\n",
    "# that does not guarantee permanent & persistent access\n",
    "barrier_data = closed_data[closed_data['data_open'] != 'Closed']\n",
    "print('Number of mostly closed data: ' + str(len(barrier_data)))\n",
    "barrier_data['data_included'].str.split(';').explode().str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadf17e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:39.157792Z",
     "start_time": "2023-11-22T00:28:39.145535Z"
    }
   },
   "outputs": [],
   "source": [
    "# It's also helpful to look at the above results in terms\n",
    "# of the combos of data available \n",
    "# We see that sometimes there are studies that share more than just \n",
    "# raw data\n",
    "barrier_data['data_included'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75e2a7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:40.684146Z",
     "start_time": "2023-11-22T00:28:40.670329Z"
    }
   },
   "outputs": [],
   "source": [
    "# Look at proportions\n",
    "barrier_data['data_included'].value_counts()/len(barrier_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a7d9ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:41.729485Z",
     "start_time": "2023-11-22T00:28:41.714766Z"
    }
   },
   "outputs": [],
   "source": [
    "# So, what are the issues with how data is being shared?\n",
    "# Most often, a study is just posting URLs -- sometimes broken even a\n",
    "# few months after being published -- which is not accessible and machine\n",
    "# readable\n",
    "closed_data['data_limitation_other'].str.split(';').explode().str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3bb623",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:42.254377Z",
     "start_time": "2023-11-22T00:28:42.236819Z"
    }
   },
   "outputs": [],
   "source": [
    "closed_data.groupby(['data_included', 'data_limitation_other']).size()/len(closed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0144150b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:43.456740Z",
     "start_time": "2023-11-22T00:28:43.441401Z"
    }
   },
   "outputs": [],
   "source": [
    "# When we just look at the studies which do share some data in a repo, \n",
    "# we see that even these have limitations in how some data is shared\n",
    "# specifically, many of these studies post data sources as URLs which\n",
    "# limits the ability of other researchers to attempt to reproduce \n",
    "# the present study. To reiterate, these are studies which\n",
    "# do make some of their data open\n",
    "# Some repos are not accessible in that you need an account or\n",
    "# permission to access the data\n",
    "barrier_data['data_limitation_other'].str.split(';').explode().str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a2c65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:44.015450Z",
     "start_time": "2023-11-22T00:28:44.000862Z"
    }
   },
   "outputs": [],
   "source": [
    "# For the studies which are making their data open but also posting URLs,\n",
    "# what kind of data are they sharing? \n",
    "# Most often, they share a subset of their raw data as open\n",
    "# Other times, they also share results, data for figures (which is source\n",
    "# data - but we try to code what the authors say in their statement), and\n",
    "# other types of data. But it's very rare that there are multiple\n",
    "# sources shared. \n",
    "barrier_sub = barrier_data[barrier_data['data_limitation_other'] == 'URLs']\n",
    "barrier_sub['data_included'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640a8a3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:45.530030Z",
     "start_time": "2023-11-22T00:28:45.513310Z"
    }
   },
   "outputs": [],
   "source": [
    "# We see similar reasons for code as for data\n",
    "closed_code['code_reasons'].str.split(';').explode().str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9096d05f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:46.911845Z",
     "start_time": "2023-11-22T00:28:46.899225Z"
    }
   },
   "outputs": [],
   "source": [
    "# We see that in general only a subset of code is shared\n",
    "# there are a few notable examples where code for multiple parts of\n",
    "# the inquiry are included -- but not all, or all just not in the\n",
    "# right type of repo to be classified as open. This indicates\n",
    "# that there is some room for stronger guidance to push authors in\n",
    "# the right direction for following open research practices. But\n",
    "# the predominance of no code at all shows there is a lot of work\n",
    "# to be done\n",
    "closed_code['code_included'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f9bca3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:48.548215Z",
     "start_time": "2023-11-22T00:28:48.539141Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now look at the mostly open studies in more detail\n",
    "mostly_open_d = open_df[open_df['data_cat'] == 'mostly_open']\n",
    "mostly_open_c = open_df[open_df['code_cat'] == 'mostly_open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dac5a22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:48.910669Z",
     "start_time": "2023-11-22T00:28:48.901353Z"
    }
   },
   "outputs": [],
   "source": [
    "len(mostly_open_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ec3813",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:49.335294Z",
     "start_time": "2023-11-22T00:28:49.326130Z"
    }
   },
   "outputs": [],
   "source": [
    "len(mostly_open_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f732d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostly_open_d['data_included']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc174eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:50.575687Z",
     "start_time": "2023-11-22T00:28:50.563338Z"
    }
   },
   "outputs": [],
   "source": [
    "mostly_open_c['code_included']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1336fb94",
   "metadata": {},
   "source": [
    "## Heatmap of data and code included crosstabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b676c6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:52.704864Z",
     "start_time": "2023-11-22T00:28:52.683008Z"
    }
   },
   "outputs": [],
   "source": [
    "# Categorize data_included and code_included fields\n",
    "hmap = open_df.groupby(['data_cat',\n",
    "                        'code_cat']).size().rename('size').reset_index()\n",
    "hmap_p = hmap.pivot(index='data_cat',\n",
    "                    columns='code_cat',\n",
    "                    values='size').fillna(0)\n",
    "\n",
    "reorder = ['open', 'mostly_open', 'mostly_closed', 'closed']\n",
    "hmap_p = hmap_p.reindex(reorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129f77c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:28:53.163449Z",
     "start_time": "2023-11-22T00:28:53.143323Z"
    }
   },
   "outputs": [],
   "source": [
    "# Look at the dataframe to make sure the plot comes out correctly\n",
    "hmap_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6609b781",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T00:29:54.297488Z",
     "start_time": "2023-11-22T00:29:52.493488Z"
    }
   },
   "outputs": [],
   "source": [
    "# Modified code from https://matplotlib.org/stable/gallery/\n",
    "# images_contours_and_fields/image_annotated_heatmap.html\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "def heatmap(data, row_labels, col_labels, ax=None,\n",
    "            cbar_kw=None, cbarlabel=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Create a heatmap from a numpy array and two lists of labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data\n",
    "        A 2D numpy array of shape (M, N).\n",
    "    row_labels\n",
    "        A list or array of length M with the labels for the rows.\n",
    "    col_labels\n",
    "        A list or array of length N with the labels for the columns.\n",
    "    ax\n",
    "        A `matplotlib.axes.Axes` instance to which the heatmap is plotted.  If\n",
    "        not provided, use current axes or create a new one.  Optional.\n",
    "    cbar_kw\n",
    "        A dictionary with arguments to `matplotlib.Figure.colorbar`.  Optional.\n",
    "    cbarlabel\n",
    "        The label for the colorbar.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to `imshow`.\n",
    "    \"\"\"\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    if cbar_kw is None:\n",
    "        cbar_kw = {}\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=90, va=\"bottom\",\n",
    "                       labelpad=20, size=14)\n",
    "\n",
    "    # Show all ticks and label them with the respective list entries.\n",
    "    ax.set_xticks(np.arange(data.shape[1]), labels=col_labels)\n",
    "    ax.set_yticks(np.arange(data.shape[0]), labels=row_labels)\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=False, bottom=True,\n",
    "                   labeltop=False, labelbottom=True)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=0, ha=\"center\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Turn spines off and create white grid.\n",
    "    ax.spines[:].set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1])-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0])-.5, minor=True)\n",
    "    \n",
    "    ax.set_xlabel('Code Openness', size=14)\n",
    "    ax.set_ylabel('Data Openness', size=14)\n",
    "    \n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False, labelsize=12)\n",
    "\n",
    "    return im, cbar\n",
    "\n",
    "def annotate_heatmap(im, data=None, valfmt=\"{x:.2f}\",\n",
    "                     textcolors=(\"black\", \"white\"),\n",
    "                     threshold=None, **textkw):\n",
    "    \"\"\"\n",
    "    A function to annotate a heatmap.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    im\n",
    "        The AxesImage to be labeled.\n",
    "    data\n",
    "        Data used to annotate.  If None, the image's data is used.  Optional.\n",
    "    valfmt\n",
    "        The format of the annotations inside the heatmap.  This should either\n",
    "        use the string format method, e.g. \"$ {x:.2f}\", or be a\n",
    "        `matplotlib.ticker.Formatter`.  Optional.\n",
    "    textcolors\n",
    "        A pair of colors.  The first is used for values below a threshold,\n",
    "        the second for those above.  Optional.\n",
    "    threshold\n",
    "        Value in data units according to which the colors from textcolors are\n",
    "        applied.  If None (the default) uses the middle of the colormap as\n",
    "        separation.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to each call to `text` used to create\n",
    "        the text labels.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "\n",
    "    # Normalize the threshold to the images color range.\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max())/2.\n",
    "\n",
    "    # Set default alignment to center, but allow it to be\n",
    "    # overwritten by textkw.\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "\n",
    "    # Get the formatter in case a string is supplied\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "\n",
    "    # Loop over the data and create a `Text` for each \"pixel\".\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[int(im.norm(data[i, j]) > threshold)])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts\n",
    "\n",
    "fig, ax = plt.subplots(dpi=300)\n",
    "\n",
    "names = ['Closed', 'Mostly\\nClosed', 'Mostly\\nOpen', 'Open']\n",
    "bounds = np.array([0, 1, 10, 100, 1000])\n",
    "im, cbar = heatmap(hmap_p.values,\n",
    "                   reversed(names),\n",
    "                   names,\n",
    "                   ax=ax,\n",
    "                   cmap=\"GnBu\",\n",
    "                   cbarlabel=\"# Studies in Our Sample\",\n",
    "                   norm=colors.BoundaryNorm(boundaries=bounds, ncolors=256))\n",
    "texts = annotate_heatmap(im, valfmt=\"{x:.0f}\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(join(ROOT_DIR, 'fig', 'fig1.png'),\n",
    "            dpi=600,\n",
    "            bbox_inches='tight') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
